{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f441485c",
   "metadata": {},
   "source": [
    "# Intro to Sklearn - Machine Learning in Python\n",
    "\n",
    "## by Corey Wade\n",
    "\n",
    "The following Jupyter Notebook is an introduction to Machine Learning in Python for ODSC West attendees on Nov. 1, 2022. We will be using pandas for data analytics, and sklearn for machine learning. A wide range of models will be covered including Linear and Logistic Regression, Decision Trees, Random Forests, and XGBoost.\n",
    "\n",
    "This presentation includes ML fundamentals covered in Corey Wade's book [Hands-on Gradient Boosting with XGBoost and scikit-learn](https://www.amazon.com/Hands-Gradient-Boosting-XGBoost-scikit-learn/dp/1839218355). Another recommend text is [Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow](https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1492032646/). For great web references, check out [Jason Brownlee's Machine Learning Mastery](https://machinelearningmastery.com/about/).\n",
    "\n",
    "Our focus is on tabular data, that is, rows and columns of data sorted in tables; this is contrasted with images and text which are considered unstructured data. When it comes to images and text, neural networks usually perform better. For tabular data, neural networks do not necessarily have an edge. We will focus on XGBoost, one the strongest ML algorithms in the world, that often has an edge in tabular data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ed5173",
   "metadata": {},
   "source": [
    "# Module 1 - Preparing data for ML with pandas\n",
    "\n",
    "The following module provides a brief introduction to pandas. To go more in-depth, try tutorial options from the official documentation: https://pandas.pydata.org/docs/getting_started/tutorials.html."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ad0d29",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f087aa",
   "metadata": {},
   "source": [
    "### Bike Rentals Dataset\n",
    "\n",
    "The [Bike Rentals dataset](https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset) is from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php). It's been modified to include correcting null values for practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdba1746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into pandas dataframe and show first 5 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4450dfe0",
   "metadata": {},
   "source": [
    "## General Data Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f32e417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show descriptive statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01115d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show correlations between columns\n",
    "# df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522f45d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show histograms and scatter plots of all columns\n",
    "#import seaborn as sns\n",
    "#sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5234c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get info on columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a891761b",
   "metadata": {},
   "source": [
    "## Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4325a580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show total null values per column\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b3b069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum null values\n",
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c5e869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows all null values\n",
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86e37e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change null values in column\n",
    "df['windspeed'] = df['windspeed'].fillna(df['windspeed'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0461ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change null values for entire dataframe\n",
    "df = df.fillna(df.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4859dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show rows\n",
    "df.iloc[[129,213,730]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a2bce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change null values by entry\n",
    "df.loc[730,'yr']=1.0\n",
    "df.loc[730, 'season']=4.0\n",
    "df.loc[[730]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05733e4",
   "metadata": {},
   "source": [
    "## Choose X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107a810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show order of columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96c3555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose X as all rows, and all columns excluding the first 2, and last 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddecf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose y as the last column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d621d92",
   "metadata": {},
   "source": [
    "## The Census Dataset\n",
    "\n",
    "The [Census Dataset](https://archive.ics.uci.edu/ml/datasets/Adult) (also called the Adult Dataset) is also from UCI. We include this dataset to balance regression with classification. Sklearn scoring metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b357eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload Census dataset with no header\n",
    "df2 = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', header=None)\n",
    "\n",
    "# define columns by name\n",
    "df2.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation',\n",
    "                  'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', \n",
    "                   'income']\n",
    "\n",
    "# show first 5 rows\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9036e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get column info\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18153e6c",
   "metadata": {},
   "source": [
    "## One-hot encoding\n",
    "\n",
    "One-hot encoding means you take each categorical column (say Color), and transform it into new columns for each value (Red, Green, Blue) as the new column header; the new columns values are 1 for presence, and 0 for absence. pd.get_dummies() often works for this purpose. sklearn includes an additional [onehotencoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) that may be useful for pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b214c5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pd.get_dummies() to transform categorical into numerical columns\n",
    "df2 = pd.get_dummies(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920550e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show df after one-hot-encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aa75c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get new number of columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e862ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select X as all rows, columns except for last 2\n",
    "\n",
    "\n",
    "# select y as last column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d32542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21586bc6",
   "metadata": {},
   "source": [
    "# Module 2 - Supervised learning with sklearn\n",
    "\n",
    "In this modules we cover the essentials of the sklearn suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd088f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45d5561",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95388c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Linear Regression\n",
    "\n",
    "\n",
    "# initialize model\n",
    "\n",
    "\n",
    "# fit model to training data\n",
    "\n",
    "\n",
    "# score model on test data (uses r2 default metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d12ef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show model coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86f2857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show model params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6095c782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show model predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86cd7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare predictions to actual results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7148362f",
   "metadata": {},
   "source": [
    "## Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c283f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to score regressors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2754eb05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85a76fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and score Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f10c113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install XGBoost to your computer\n",
    "import sys\n",
    "!{sys.executable} -m pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b4b3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and score XGBoost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6040640e",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67da76b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write function to score classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72947fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and score Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c30c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and score Decision Tree for classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb4f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and score Random Forest for classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9cbf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and score XGBoost for classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7afa1bb",
   "metadata": {},
   "source": [
    "## Predictions / Scoring Metrics\n",
    "\n",
    "Making meaningful predictions is arguably the most important part of Machine Learning. You use pandas or numpy arrays to make predictions with sklearn.\n",
    "\n",
    "There are many scoring metrics available in sklearn, especially for classification. See your options here: https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd6e5f3",
   "metadata": {},
   "source": [
    "### Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed310b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build XGBoost model\n",
    "\n",
    "# get predictions for test set\n",
    "\n",
    "# for rmse, import mse first\n",
    "#from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3299d32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show descriptive stats for y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba311464",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c645bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at last 5 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bec669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict last 2 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d114c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check last 2 rows actual value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f3b73f",
   "metadata": {},
   "source": [
    "### NumPy Arrays\n",
    "\n",
    "It's often easier to make predictions from ML models when your inputs are NumPy Arrays. Then you don't have worry about column names. Pandas DataFrames, or NumPy Arrays are okay. NumPy Arrays are better for single rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a932476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to numpy arrays\n",
    "import numpy as np\n",
    "X_train_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "y_train_np = np.array(y_train)\n",
    "y_test_np = np.array(y_test)\n",
    "\n",
    "# train model on numpy arrays\n",
    "model = XGBRegressor()\n",
    "model.fit(X_train_np, y_train_np)\n",
    "y_pred_np = model.predict(X_test_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7602bf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select last row to modify\n",
    "X_test.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f68967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show predictions\n",
    "model.predict(np.array([[3.0, 0.0, 8.0, 0.0, 0.0, 0.0, 2, 0.676667, 0.624388, 0.817500, 0.222633]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f94714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the prediction works, even though no column headers have been provided\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba90710e",
   "metadata": {},
   "source": [
    "### Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9f8f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show confusion matrix and classification report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ff08b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the f1-score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f35d259",
   "metadata": {},
   "source": [
    "## Your Turn!\n",
    "\n",
    "Try different models to get the best f1-score on the census dataset using random_state=0. You must use default params! (Changing params coming in Module 4 of this notebook.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c955cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try out different models using f1-scoring metric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394f788f",
   "metadata": {},
   "source": [
    "# Module 3 - Cross-validation with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a009b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cross_val_score to use cross-validation\n",
    "\n",
    "# choose your model\n",
    "\n",
    "# get scores on five folds of data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad60e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199edbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use KFold for shuffled, consistent folds \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2977fd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use stratified Kfold for classification to balance all test sets\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "ksfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "#clf=XGBClassifier()\n",
    "#f1 = cross_val_score(clf, X2, y2, scoring='f1', cv=ksfold)\n",
    "#print(f1.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf9dbd6",
   "metadata": {},
   "source": [
    "# Module 4 - Fine-tuning models with sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e092346c",
   "metadata": {},
   "source": [
    "## GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d598cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use GridSearchCV to search grid of hyperparameters for best values\n",
    "\n",
    "# GridSearch uses a dictionary of parameters to find optimal values\n",
    "\n",
    "# GridSearchCV takes an ML model, the dictionary of params, etc. as inputs\n",
    "\n",
    "\n",
    "# you fit gridsearch on training data just like an ml model\n",
    "\n",
    "# now you can access the best parameters, with the best score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8ceff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function includes all steps in the cell above with XGBoost as the default model\n",
    "def grid_search(params, reg=XGBRegressor()):\n",
    "    grid_reg = GridSearchCV(reg, params, scoring='neg_mean_squared_error', cv=kfold)\n",
    "    grid_reg.fit(X_train, y_train)\n",
    "    best_params = grid_reg.best_params_\n",
    "    print(\"Best params:\", best_params)\n",
    "    best_score = (-grid_reg.best_score_)**0.5\n",
    "    print(\"Best score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9d2376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf564763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search 2 params - 12 models total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2616ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add additional params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccf9829",
   "metadata": {},
   "source": [
    "## RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5376da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCV works the same way, but checks n (10 by default) random combinations\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "def random_search(params, reg=XGBRegressor()):\n",
    "    grid_reg = RandomizedSearchCV(reg, params, scoring='neg_mean_squared_error', cv=kfold, n_iter=10, random_state=0)\n",
    "    grid_reg.fit(X_train, y_train)\n",
    "    best_params = grid_reg.best_params_\n",
    "    print(\"Best params:\", best_params)\n",
    "    best_score = (-grid_reg.best_score_)**0.5\n",
    "    print(\"Best score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc41eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following is a reasonable starting sample of params\n",
    "random_search(params={'subsample':[0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "        'colsample_bynode':[0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "        'colsample_bytree':[0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "        'colsample_bylevel':[0.5, 0.6, 0.7, 0.8, 0.9, 1], \n",
    "        'min_child_weight':[1, 2, 3, 4, 5], \n",
    "        'learning_rate':[0.001, 0.01, 0.1, 0.2, 0.4, 0.6], \n",
    "        'max_depth':[2, 3, 4, 5, 6, 8, 10], \n",
    "        'n_estimators':[25, 50, 100, 200, 400]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a933403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust based on results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5afe69",
   "metadata": {},
   "source": [
    "## Your turn!\n",
    "\n",
    "Try your own random and grid searches to get the best possible cv score on 5 folds using random_state=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037b1038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try your own random searches, and/or grid searches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eab774",
   "metadata": {},
   "source": [
    "# Module 5 - Feature Importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8bd499",
   "metadata": {},
   "source": [
    "## Finalize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f79ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose your best model, fit on your data, then test against unseen data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed3962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the influence of each column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe5d360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip columns and feature_importances_ into dict\n",
    "feature_dict = dict(zip(X.columns, model.feature_importances_))\n",
    "\n",
    "# import operator\n",
    "import operator\n",
    "\n",
    "# sort dict by values (as list of tuples)\n",
    "sorted(feature_dict.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e437ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
